{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de Données\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"figures\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.8, 9.6)\n",
    "\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "loading = pd.read_csv(path + 'velibLoading.csv', sep=\" \")\n",
    "loading.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velibAdds = pd.read_csv(path + 'velibAdds.csv', sep=\" \")\n",
    "velibAdds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velibAdds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_stations_on_hills = 0\n",
    "for i in range(1189):\n",
    "    if velibAdds.iloc[i, 2] == 1:\n",
    "        number_of_stations_on_hills += 1\n",
    "print(\"{0:.2%}\".format(number_of_stations_on_hills / 1189))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = loading.columns.size\n",
    "Time = np.linspace(1, p, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Time, loading.transpose()[1], linewidth=2, color='blue')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Loading')\n",
    "plt.title(velibAdds.names[1])\n",
    "plt.vlines(x=np.linspace(1, p, 8), ymin=0, ymax=1, colors=\"black\", linestyle=\"dotted\")\n",
    "save_fig('euryale_station_loading')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "for i in range(1, 17):\n",
    "    plt.subplot(4, 4, i)\n",
    "    plt.plot(Time, loading.transpose()[i], linewidth=2, color='blue')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Loading')\n",
    "    plt.title(velibAdds.names[i])\n",
    "    plt.vlines(x=np.linspace(1, p, 8), ymin=0, ymax=1, colors=\"black\", linestyle=\"dotted\")\n",
    "\n",
    "#plt.suptitle('Loading of the 16 First Stations', fontsize='x-large')\n",
    "save_fig('16_first_loading_plots')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplot(x, medianprops, title=None):\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    plt.boxplot(x, medianprops=medianprops)\n",
    "    plt.vlines(x=np.linspace(1, p, 8), ymin=0, ymax=1, colors=\"blue\", linestyle=\"dotted\", linewidth=3)\n",
    "    plt.xticks(np.arange(0, 168, 5), labels=np.arange(0, 168, 5), fontsize=10)\n",
    "    if title:\n",
    "        plt.title(title, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medianprops = dict(linestyle='-.', linewidth=5, color='firebrick')\n",
    "\n",
    "plot_boxplot(loading, medianprops, title=None)\n",
    "save_fig('boxplot_of_variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 12  # time\n",
    "t = 3  # shift\n",
    "\n",
    "plt.scatter(loading.iloc[:, t], loading.iloc[:, t + h])\n",
    "#plt.title(\"Loading at time {} vs at time {}\".format(t+h, t), fontsize=14)\n",
    "save_fig('loading_shift_correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4)\n",
    "for i in range(3):\n",
    "    for j in range(1, 5):\n",
    "        axs[i, j - 1].scatter(loading.iloc[:, i * 4 + j],\n",
    "                              loading.iloc[:, i * 4 + j + 1],\n",
    "                              alpha=.7)\n",
    "        axs[i, j - 1].set_title(\"time {} vs time {}\".format(i * 4 + j + 1, i * 4 + j))\n",
    "\n",
    "save_fig('mult_loading_shift_correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = loading.corr()\n",
    "\n",
    "plt.figure(figsize=(20, 9))\n",
    "plt.subplot(1, 2, 1)\n",
    "#plt.title('Total Correlations', fontsize=20)\n",
    "sns.heatmap(corr_matrix, xticklabels=False, yticklabels=False, cmap=\"viridis\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "#plt.title('Sub-correlation (Monday)', fontsize=20)\n",
    "sns.heatmap(corr_matrix.iloc[:24, :24],\n",
    "            xticklabels=True,\n",
    "            yticklabels=True,\n",
    "            cmap=\"viridis\")\n",
    "save_fig('loading_correlation_total_day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude = velibAdds.longitude\n",
    "latitude = velibAdds.latitude\n",
    "on_hill = (velibAdds.bonus == 1)  # on recupere les valeurs ou bonus=1 i.e. sur une colline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim = (2.2222, 2.4795)\n",
    "plt.ylim = (48.8064, 48.9152)\n",
    "plt.scatter(longitude[~on_hill], latitude[~on_hill])\n",
    "plt.scatter(longitude[on_hill], latitude[on_hill], marker=\"2\")\n",
    "plt.legend(labels=['Not On Hill', 'On Hill'], fontsize='x-large')\n",
    "plt.xlabel('Longitudes')\n",
    "plt.ylabel('Latitudes')\n",
    "#plt.title('Location of Stations in Paris', fontsize=14)\n",
    "save_fig('location_of_stations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(loading[on_hill], medianprops)\n",
    "save_fig('boxplot_of_hill_stations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(loading[~on_hill], medianprops)\n",
    "save_fig('boxplot_of_not_hill_stations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "\n",
    "Given that we have many variables (168 variables), we use PCA to better understand the meaning of these variables and select only a few of them. <br>\n",
    "Our data does not need to be scaled before performing PCA as the loading is a number between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 15\n",
    "pca = PCA(n_components=n_components)\n",
    "loading_pca = pca.fit_transform(loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first plot the percentage of variance explained by the first 15 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(pca.explained_variance_.size)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "ax[0].bar(x, pca.explained_variance_ratio_)\n",
    "ax[0].plot(pca.explained_variance_ratio_, color='black')\n",
    "ax[0].set_xlabel('Principal Components', fontsize=16)\n",
    "ax[0].set_ylabel('Explained Variance', fontsize=16)\n",
    "#ax[0].set_title('Explained Variance Ratios',fontsize=25)\n",
    "\n",
    "for p in ax[0].patches:\n",
    "    text = str(np.round(p.get_height(), 2) * 100) + '%'\n",
    "    ax[0].annotate(text=text,\n",
    "                   xy=(p.get_x() + p.get_width() / 2., p.get_height() + 0.01),\n",
    "                   fontsize='large',\n",
    "                   ha='center',\n",
    "                   va='center')\n",
    "\n",
    "ax[1].bar(x + 1, np.cumsum(pca.explained_variance_ratio_), width=.7)\n",
    "ax[1].set_ylabel('Shared Variance', fontsize=16)\n",
    "ax[1].set_xlabel('Principal Components', fontsize=16)\n",
    "#ax[1].set_title('Cumulative Sum of Variance Ratio',fontsize=25)\n",
    "\n",
    "for p in ax[1].patches:\n",
    "    text = str(np.round(p.get_height(), 2) * 100) + '%'\n",
    "    ax[1].annotate(text=text,\n",
    "                   xy=(p.get_x() + p.get_width() / 2., p.get_height() + 0.01),\n",
    "                   fontsize='large',\n",
    "                   ha='center',\n",
    "                   va='center')\n",
    "\n",
    "save_fig('explained_var_ratio_and_cumulative')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the variance is contained in the first two components (around 60%), but there is still some important imformation in some of the following components. We explain 80% of the variance with the first seven components. <br>\n",
    "On the graph 'Explained Variance Ratios', the curve of explained variance ratios is bent over the 6th principal component.<br>\n",
    "We therefore choose to work with the first 6 components, given that after the sixth component, the cumulated sum of shared variance increases very slowly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also analyze the boxplot of the coordinates of the bike stations on the first fifteen principal axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(loading_pca)\n",
    "plt.axhline(0, c='b', alpha=.2)\n",
    "plt.xlabel('Principal Components', fontsize=16)\n",
    "#plt.title('Boxplot of Principal Components',fontsize='xx-large')\n",
    "save_fig('boxplot_of_pca')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These boxplots give us the same information as before. The first two components are the ones with the biggest variance, and after the sixth component, variance decreases very slowly. <br>\n",
    "The medians are centered on 0 after the 3rd principal component and the extent of boxplots is constant after the 6th principal component. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the projection of all of the bike stations onto the plane formed by the first two principal axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(loading_pca[:, 0][~on_hill],\n",
    "            loading_pca[:, 1][~on_hill],\n",
    "            color='b',\n",
    "            label='Not On Hill')\n",
    "plt.scatter(loading_pca[:, 0][on_hill],\n",
    "            loading_pca[:, 1][on_hill],\n",
    "            color='r',\n",
    "            label='On Hill')\n",
    "plt.axhline(0, linestyle='--', color='black')\n",
    "plt.axvline(0, linestyle='--', color='black')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "#plt.title('Individuals Map - PCA')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "save_fig('map_of_individuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that there might be a cluster near the bottom left corner, and amongst this cluster are most of the bike stations located on a hill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then plot the circle of correlation for the first two components, which we zoom in on to better appreciate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord1 = pca.components_[0] * np.sqrt(pca.explained_variance_[0])\n",
    "coord2 = pca.components_[1] * np.sqrt(pca.explained_variance_[1])\n",
    "\n",
    "for i, j, nom in zip(coord1, coord2, loading.columns):\n",
    "    plt.text(i, j, nom)\n",
    "    plt.arrow(0, 0, i, j, color='black', alpha=.2)\n",
    "\n",
    "#plt.title('Variables Factor Map - PCA', fontsize=14)\n",
    "plt.xlabel('Dimension 1 ')\n",
    "plt.ylabel('Dimension 2 ')\n",
    "plt.grid(True)\n",
    "save_fig('variables_correlation_1_2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that all of the variables take positive values on the first principal axis. For the second axis, positive values tend to correspond to daytime hours (14 to 18), while negative values correspond to nighttime hours (23 to 05). However, all of the variables are very far away from the edge of the circle of radius 1. Therefore we can deduce that :\n",
    "\n",
    "Principal Component 1: overall loading \n",
    "\n",
    "Principal Component 2: contrast between day and night"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also plot the circle of correlation for components 1 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord3 = pca.components_[2] * np.sqrt(pca.explained_variance_[2])\n",
    "\n",
    "for i, j, nom in zip(coord1, coord3, loading.columns):\n",
    "    plt.text(i, j, nom)\n",
    "    plt.arrow(0, 0, i, j, color='black', alpha=.1)\n",
    "\n",
    "#plt.title('Variables Factor Map - PCA', fontsize=14)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 3')\n",
    "plt.grid(True)\n",
    "save_fig('variables_correlation_1_3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By observing the third principal component, we find that most of the variables with positive coordinates correspond to the days of the weekend, while most of the varibles with negative coordinates correspond to weekdays. We can conclude that:\n",
    "\n",
    "Principal Component 3: contrast between weekdays and the weekend.\n",
    "\n",
    "However, it is important to remember that this analysis is mostly inconclusive because the arrows are all very short in norms, which means that the correlation with either dimension is not very strong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 1)\n",
    "x = np.arange(len(pca.components_[1]))\n",
    "for i in range(6):\n",
    "    axs[i].plot(x, pca.components_[i])\n",
    "    axs[i].set_ylabel(\"PC \" + str(i + 1))\n",
    "\n",
    "#fig.suptitle('Principal Components', fontsize=14)\n",
    "save_fig('graphs_pca')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dic_hill = {1: 'Not On Hill', 2: 'On Hill'}\n",
    "\n",
    "\n",
    "def plot_pca(l_pca, fig, ax, nbc, nbc2):\n",
    "    for i in range(2):\n",
    "        xs = l_pca[velibAdds.bonus == i, nbc - 1]\n",
    "        ys = l_pca[velibAdds.bonus == i, nbc2 - 1]\n",
    "        label = label_dic_hill[i + 1]\n",
    "        color = cmaps(i)\n",
    "        ax.scatter(xs, ys, color=color, alpha=.8, s=1, label=label)\n",
    "        ax.set_xlabel(\"PC %d: %.2f%%\" %\n",
    "                      (nbc, pca.explained_variance_ratio_[nbc - 1] * 100),\n",
    "                      fontsize=10)\n",
    "        ax.set_ylabel(\"PC %d: %.2f%%\" %\n",
    "                      (nbc2, pca.explained_variance_ratio_[nbc2 - 1] * 100),\n",
    "                      fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaps = plt.get_cmap(\"Set1\")\n",
    "\n",
    "fig = plt.figure()\n",
    "for nbc, nbc2, count in [(1, 2, 1), (1, 3, 2), (1, 4, 3), (2, 3, 5), (2, 4, 6),\n",
    "                         (3, 4, 9)]:\n",
    "    ax = fig.add_subplot(3, 3, count)\n",
    "    plot_pca(loading_pca, fig, ax, nbc, nbc2)\n",
    "\n",
    "plt.legend(loc='best',\n",
    "           bbox_to_anchor=(1.8, 2),\n",
    "           markerscale=8,\n",
    "           fontsize='large')\n",
    "#plt.suptitle('Principal Components from 1 to 4', fontsize=14)\n",
    "save_fig('scatter_of_1_4_pc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAH sur les données brutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "height = 30.5\n",
    "Z = sch.linkage(loading, method=\"ward\", metric=\"euclidean\")\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sch.dendrogram(Z, no_labels=True)\n",
    "plt.axhline(height, color='black', alpha=.8, linestyle='--')\n",
    "plt.ylabel('Euclidean Distance', fontsize='x-large')\n",
    "#plt.title(\"Ascending Hierarchical Clustering : Dendrogram\", fontsize='xx-large')\n",
    "save_fig('AHC_dendrogram_raw')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = Z[:, 2]  # Décroissance des sauts\n",
    "x = np.arange(len(heights)) + 1\n",
    "heights = sorted(heights, reverse=True)\n",
    "\n",
    "plt.plot(x[:16], heights[:16], '-o')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Height', fontsize=14)\n",
    "plt.axvline(5, color='black', alpha=3, linestyle='--')\n",
    "#plt.title(\"Number of clusters\",fontsize='xx-large')\n",
    "save_fig('AHC_heights_raw')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_cah = sch.fcluster(Z, t=height, criterion='distance')\n",
    "newvelib = velibAdds.copy()\n",
    "newvelib['group'] = groups_cah\n",
    "n_clusters = np.max(groups_cah)\n",
    "print('Number of clusters:', n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pof\n",
    "\n",
    "colors = sns.color_palette(\"husl\", n_clusters).as_hex()\n",
    "grouped = newvelib.groupby('group')\n",
    "mapbox_access_token = \"pk.eyJ1IjoibGFsb3VlYSIsImEiOiJja2tpaGdsbW0weWplMnZxdHl5cG1ncW8xIn0.NG1rULNFLX4zplmUV0WPoQ\"\n",
    "\n",
    "fig = go.Figure()\n",
    "for i in range(n_clusters):\n",
    "    df_group = grouped.get_group(i + 1)\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            name='Cluster {}'.format(i + 1),\n",
    "            lon=df_group.longitude.values,\n",
    "            lat=df_group.latitude.values,\n",
    "            mode='markers',\n",
    "            marker=dict(size=7, color=colors[i], opacity=0.8),\n",
    "            hovertemplate=df_group.names,\n",
    "        ))\n",
    "fig.update_layout(\n",
    "    title_text='CAH Clusters of Velib Stations',\n",
    "    mapbox=go.layout.Mapbox(accesstoken=mapbox_access_token,\n",
    "                            zoom=12,\n",
    "                            center={\n",
    "                                'lon': 2.3425123048878604,\n",
    "                                'lat': 48.85920718597386\n",
    "                            }),\n",
    "    autosize=False,\n",
    "    width=1500,\n",
    "    height=850,\n",
    ")\n",
    "pof.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['v', '^', 'o', 's', 'p', '*']\n",
    "\n",
    "for i, marker in zip(np.arange(n_clusters), markers):\n",
    "    temp = grouped.get_group(i + 1)\n",
    "    plt.scatter(temp.longitude.values,\n",
    "                temp.latitude.values,\n",
    "                color=colors[i],\n",
    "                label='Cluster {}'.format(i + 1),\n",
    "                marker=marker)\n",
    "\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "#plt.title('CAH clusters')\n",
    "plt.legend(fontsize=16)\n",
    "save_fig('CAH_clusters_raw')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAH sur les CP de l'ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 32\n",
    "loadingCP = loading_pca[:, :6]\n",
    "Z = sch.linkage(loadingCP, method=\"ward\", metric=\"euclidean\")\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sch.dendrogram(Z, no_labels=True)\n",
    "plt.axhline(height, color='black', alpha=.5, linestyle='--')\n",
    "plt.ylabel('Distance')\n",
    "#plt.title(\"CAH\", fontsize='xx-large')\n",
    "plt.savefig(\"CAH_PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_cah_acp = sch.fcluster(Z, t=height, criterion='distance')\n",
    "newvelib = velibAdds.copy()\n",
    "newvelib['group'] = groups_cah_acp\n",
    "n_clusters = np.max(groups_cah_acp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"husl\", n_clusters).as_hex()\n",
    "grouped = newvelib.groupby('group')\n",
    "mapbox_access_token = \"pk.eyJ1IjoibGFsb3VlYSIsImEiOiJja2tpaGdsbW0weWplMnZxdHl5cG1ncW8xIn0.NG1rULNFLX4zplmUV0WPoQ\"\n",
    "dicts = {}\n",
    "\n",
    "fig = go.Figure()\n",
    "for i in range(n_clusters):\n",
    "    df_group = grouped.get_group(i + 1)\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(name='Cluster {}'.format(i + 1),\n",
    "                         lon=df_group.longitude.values,\n",
    "                         lat=df_group.latitude.values,\n",
    "                         mode='markers',\n",
    "                         marker=dict(size=5, color=colors[i]),\n",
    "                         hovertemplate=df_group.names))\n",
    "fig.update_layout(\n",
    "    title_text='CAH Clusters of Velib Stations',\n",
    "    mapbox=go.layout.Mapbox(accesstoken=mapbox_access_token,\n",
    "                            zoom=12,\n",
    "                            center={\n",
    "                                'lon': 2.3425123048878604,\n",
    "                                'lat': 48.85920718597386\n",
    "                            }),\n",
    "    autosize=False,\n",
    "    width=1500,\n",
    "    height=850,\n",
    ")\n",
    "pof.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_table(classe1, classe2):\n",
    "    table = pd.crosstab(classe1,\n",
    "                        classe2,\n",
    "                        rownames=['classes ACP'],\n",
    "                        colnames=['classes données brutes'])\n",
    "    a = np.zeros(np.shape(table)[0])\n",
    "    b = np.zeros(np.shape(table)[0])\n",
    "    for j in range(0, np.shape(table)[0]):\n",
    "        for i in range(0, np.shape(table)[0]):\n",
    "            if a[j] < table[i][j]:\n",
    "                a[j] = table[i][j]\n",
    "                b[j] = i\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"max colonne\", a)\n",
    "    print(\"j=\", b)\n",
    "    print(\"\")\n",
    "    #tablebis = np.copy(table)\n",
    "    n = np.shape(table)[0]\n",
    "    tablebis = pd.DataFrame(columns=[str(i) for i in range(n)])\n",
    "\n",
    "    for k in range(n):\n",
    "        tablebis[str(k)] = table[b[k]][:]\n",
    "        #tablebis[k][:] = table[b[k]][:]\n",
    "\n",
    "    return tablebis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_table(groups_cah - 1, groups_cah_acp - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En sélectionnant le même nombre de classes : 4, la CAH sur les 6 CP de l'ACP et la CAH sur les données brutes donnent les mêmes résultats ie elles classent les individus dans les mêmes clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the $k$-means method to regroup the individuals projected into the space formed by the first six principal axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadingCP = loading_pca[:, 0:6]\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(loadingCP)\n",
    "kclassesACP = kmeans.labels_\n",
    "\n",
    "pd.DataFrame(kclassesACP).hist()\n",
    "save_fig('histplot_of_3_axes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same, but this time using the individuals in the full space $\\mathbb{R}^{168}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(scale(loading))\n",
    "kclasses = kmeans.labels_\n",
    "pd.DataFrame(kclasses).hist()\n",
    "save_fig('histplot_of_raw_data_classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function cross_table() we compare these two groups of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_table(kclassesACP, kclasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross table shows that these two groups of clusters are practically the same. This can also be observed by comparing the two histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the indiviuals into the plane formed by the first two principal axis and we separate the previous clusters by color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1 = loading_pca[:, 0]\n",
    "pc2 = loading_pca[:, 1]\n",
    "coul = ['b', 'r', 'g', 'y', 'm', 'c']\n",
    "n_clusters = 6\n",
    "# Choix des options\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "# Exécution de l'algorithme\n",
    "y_pred = kmeans.fit_predict(loadingCP)\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "for i, j, indcoul in zip(pc1, pc2, kclasses):\n",
    "    plt.text(i, j, \"o\", color=coul[indcoul], fontweight='black')\n",
    "\n",
    "plt.axis((-8, 8, -8, 8))\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)\n",
    "#plt.title('Individuals by Class Factor Map - PCA (with plotted cluster centroids)', fontsize=14)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "save_fig('clusters_with_centers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "y_pred = kmeans.fit_predict(scale(loading))\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "plt.figure(figsize=(24, 12))\n",
    "plt.boxplot(scale(loading), medianprops=medianprops)\n",
    "plt.boxplot(centers,\n",
    "            medianprops=dict(linestyle='dashed', linewidth=5, color='crimson'))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Loading')\n",
    "#plt.title('K-Means on Raw Data')\n",
    "save_fig('kmeans_raw')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = loading.columns.size\n",
    "fig, ax = plt.subplots(3, 2, figsize=(20, 8))\n",
    "\n",
    "arr = [(i, j) for i in [0, 1, 2] for j in [0, 1]]\n",
    "k = 0\n",
    "for i, j in arr:\n",
    "    ax[i, j].plot(Time, centers[k], linewidth=2, color=coul[k])\n",
    "    ax[i, j].vlines(x=np.linspace(1, p, 8),\n",
    "                    ymin=np.min(centers[k]),\n",
    "                    ymax=np.max(centers[k]),\n",
    "                    color=\"black\",\n",
    "                    linestyle=\"dotted\",\n",
    "                    linewidth=3)\n",
    "    ax[i, j].set_xlabel('Time')\n",
    "    ax[i, j].set_ylabel('Loading ' + str(k))\n",
    "    ax[i, j].set_title(f'Mean Loading of Cluster {k+1}')\n",
    "    k += 1\n",
    "\n",
    "save_fig('loading_of_clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters = [[[0]], [[0]], [[0]], [[0]]]\n",
    "# for k in range(len(y_pred)):\n",
    "#     num = y_pred[k]\n",
    "#     clusters[num].append([loading.iloc[k, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2, 2, figsize=(20, 8))\n",
    "\n",
    "# ax[0, 0].boxplot(clusters[0],\n",
    "#                  medianprops=dict(linestyle='dashed',\n",
    "#                                   linewidth=5,\n",
    "#                                   color=coul[0]))\n",
    "# ax[0, 0].set_xlabel('Time')\n",
    "# ax[0, 0].set_ylabel('Loading ' + str(0))\n",
    "\n",
    "# ax[0, 1].boxplot(clusters[1],\n",
    "#                  medianprops=dict(linestyle='dashed',\n",
    "#                                   linewidth=5,\n",
    "#                                   color=coul[1]))\n",
    "# ax[0, 1].set_xlabel('Time')\n",
    "# ax[0, 1].set_ylabel('Loading ' + str(1))\n",
    "\n",
    "# ax[1, 0].boxplot(clusters[2],\n",
    "#                  medianprops=dict(linestyle='dashed',\n",
    "#                                   linewidth=5,\n",
    "#                                   color=coul[2]))\n",
    "# ax[1, 0].set_xlabel('Time')\n",
    "# ax[1, 0].set_ylabel('Loading ' + str(2))\n",
    "\n",
    "# ax[1, 1].boxplot(clusters[3],\n",
    "#                  medianprops=dict(linestyle='dashed',\n",
    "#                                   linewidth=5,\n",
    "#                                   color=coul[3]))\n",
    "# ax[1, 1].set_xlabel('Time')\n",
    "# ax[1, 1].set_ylabel('Loading ' + str(3))\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
    "\n",
    "X = loading_pca.copy()\n",
    "kmeans_per_k = [\n",
    "    KMeans(n_clusters=k, random_state=42).fit(X) for k in range(1, 10)\n",
    "]\n",
    "inertias = [model.inertia_ for model in kmeans_per_k]\n",
    "silhouette_score(X, kmeans.labels_)\n",
    "silhouette_scores = [\n",
    "    silhouette_score(X, model.labels_) for model in kmeans_per_k[1:]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 9))\n",
    "\n",
    "for k in (3, 4, 5, 6):\n",
    "    plt.subplot(2, 2, k - 2)\n",
    "\n",
    "    y_pred = kmeans_per_k[k - 1].labels_\n",
    "    silhouette_coefficients = silhouette_samples(X, y_pred)\n",
    "\n",
    "    padding = len(X) // 30\n",
    "    pos = padding\n",
    "    ticks = []\n",
    "    for i in range(k):\n",
    "        coeffs = silhouette_coefficients[y_pred == i]\n",
    "        coeffs.sort()\n",
    "        cmap = matplotlib.cm.get_cmap(\"Spectral\")\n",
    "        color = cmap(i / k)\n",
    "        plt.fill_betweenx(np.arange(pos, pos + len(coeffs)),\n",
    "                          0,\n",
    "                          coeffs,\n",
    "                          facecolor=color,\n",
    "                          edgecolor=color,\n",
    "                          alpha=0.7)\n",
    "        ticks.append(pos + len(coeffs) // 2)\n",
    "        pos += len(coeffs) + padding\n",
    "\n",
    "    plt.gca().yaxis.set_major_locator(FixedLocator(ticks))\n",
    "    plt.gca().yaxis.set_major_formatter(FixedFormatter(range(k)))\n",
    "    if k in (3, 5):\n",
    "        plt.ylabel(\"Cluster\")\n",
    "\n",
    "    if k in (5, 6):\n",
    "        plt.gca().set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        plt.xlabel(\"Silhouette Coefficient\")\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "\n",
    "    plt.axvline(x=silhouette_scores[k - 2],\n",
    "                color=\"red\",\n",
    "                linestyle=\"--\",\n",
    "                label='S.C mean')\n",
    "    plt.title(\"$k={}$\".format(k), fontsize=16)\n",
    "\n",
    "save_fig('silhouette_coefficient')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, 10), inertias, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Inertia\", fontsize=14)\n",
    "#plt.title('Intertia vs Number of classes')\n",
    "save_fig('inertia_classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have plotted the silhouette coefficients according to the number of clusters. It is clear that using 5 or 6 clusters is a bad idea because some of the clusters have a lower than average silhouette coefficient. The answer is ambiguous, since the plots with 3 or 4 clusters reveal that both models are adequate. Both models do have misplaced samples and the 3 cluster model does have a cluster that contain a lot of samples. It also has a better average silhouette coefficient. The 4 clusters model does have more well distributed samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian mixture model on PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "\n",
    "def plot_centroids(centroids, weights=None, circle_color='w', cross_color='k'):\n",
    "    if weights is not None:\n",
    "        centroids = centroids[weights > weights.max() / 10]\n",
    "    plt.scatter(centroids[:, 0],\n",
    "                centroids[:, 1],\n",
    "                marker='o',\n",
    "                s=30,\n",
    "                linewidths=8,\n",
    "                color=circle_color,\n",
    "                zorder=10,\n",
    "                alpha=0.9)\n",
    "    plt.scatter(centroids[:, 0],\n",
    "                centroids[:, 1],\n",
    "                marker='x',\n",
    "                s=50,\n",
    "                linewidths=50,\n",
    "                color=cross_color,\n",
    "                zorder=11,\n",
    "                alpha=1)\n",
    "\n",
    "\n",
    "def plot_gaussian_mixture(clusterer, X, resolution=1000, show_ylabels=True):\n",
    "    mins = X.min(axis=0) - 0.1\n",
    "    maxs = X.max(axis=0) + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], resolution),\n",
    "                         np.linspace(mins[1], maxs[1], resolution))\n",
    "    Z = -clusterer.score_samples(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx,\n",
    "                 yy,\n",
    "                 Z,\n",
    "                 norm=LogNorm(vmin=1.0, vmax=30.0),\n",
    "                 levels=np.logspace(0, 2, 12))\n",
    "    plt.contour(xx,\n",
    "                yy,\n",
    "                Z,\n",
    "                norm=LogNorm(vmin=1.0, vmax=30.0),\n",
    "                levels=np.logspace(0, 2, 12),\n",
    "                linewidths=1,\n",
    "                colors='k')\n",
    "\n",
    "    Z = clusterer.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contour(xx, yy, Z, linewidths=2, colors='r', linestyles='dashed')\n",
    "\n",
    "    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
    "    plot_centroids(clusterer.means_, clusterer.weights_)\n",
    "\n",
    "    plt.xlabel(\"Dimension 1\", fontsize=14)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"Dimension 2\", fontsize=14)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GaussianMixture(n_components=n_clusters, n_init=10, random_state=42)\n",
    "gm.fit(loading_pca[:, :2])\n",
    "labels_gm = gm.predict(loading_pca[:, :2])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_gaussian_mixture(gm, loading_pca[:, :2])\n",
    "save_fig(\"Gaussian_mix_1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=labels_gm, s=40, cmap='viridis')\n",
    "#plt.title('Gaussian mixture clustering - PCA (with plotted cluster centroids)', fontsize=14)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "save_fig(\"Gaussian_mix_2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gms_per_k = [\n",
    "    GaussianMixture(n_components=k, n_init=10,\n",
    "                    random_state=42).fit(loading_pca[:, :2])\n",
    "    for k in range(1, 11)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bics = [model.bic(loading_pca[:, :2]) for model in gms_per_k]\n",
    "aics = [model.aic(loading_pca[:, :2]) for model in gms_per_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(range(1, 11), bics, \"bo-\", label=\"BIC\")\n",
    "plt.plot(range(1, 11), aics, \"go--\", label=\"AIC\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Information Criterion\", fontsize=12)\n",
    "plt.axis([1, 9.5, np.min(aics) - 50, np.max(aics) + 50])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_bic = np.infty\n",
    "\n",
    "for k in range(1, 11):\n",
    "    for covariance_type in (\"full\", \"tied\", \"spherical\", \"diag\"):\n",
    "        bic = GaussianMixture(n_components=k,\n",
    "                              n_init=10,\n",
    "                              covariance_type=covariance_type,\n",
    "                              random_state=42).fit(X).bic(X)\n",
    "        if bic < min_bic:\n",
    "            min_bic = bic\n",
    "            best_k = k\n",
    "            best_covariance_type = covariance_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_covariance_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A faire : tables de contingence : comparaison des différentes classifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_table(kclasses, groups_cah - 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
